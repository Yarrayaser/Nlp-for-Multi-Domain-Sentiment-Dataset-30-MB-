{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-02T21:17:15.621339Z","iopub.execute_input":"2022-06-02T21:17:15.621921Z","iopub.status.idle":"2022-06-02T21:17:15.632819Z","shell.execute_reply.started":"2022-06-02T21:17:15.621874Z","shell.execute_reply":"2022-06-02T21:17:15.631934Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"/kaggle/input/gnewsvector/GoogleNews-vectors-negative300.bin\n/kaggle/input/ass4-nlp-test/negative.review\n/kaggle/input/ass4-nlp-test/positive.review\n/kaggle/input/sentimentanalyzer/negative.review\n/kaggle/input/positivereview/positive.review\n/kaggle/input/ass4-nlp-train/negative.review\n/kaggle/input/ass4-nlp-train/dvdnegative.review\n/kaggle/input/ass4-nlp-train/positive.review\n/kaggle/input/ass4-nlp-train/dvdpositive.review\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# read files and take only review_text and make shuffled on data","metadata":{}},{"cell_type":"code","source":"import nltk\nnltk.download('punkt')\nnltk.download('wordnet')\nimport numpy as np\n\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.linear_model import LogisticRegression\nfrom bs4 import BeautifulSoup\n#read data from file and get only review_test data\nbook_positive_reviews = BeautifulSoup(open('../input/ass4-nlp-train/positive.review').read())\nbook_positive_reviews = book_positive_reviews.findAll('review_text')\n\nbook_negative_reviews = BeautifulSoup(open('../input/ass4-nlp-train/negative.review').read())\nbook_negative_reviews = book_negative_reviews.findAll('review_text')\n\ndvd_positive_reviews = BeautifulSoup(open('../input/ass4-nlp-train/dvdnegative.review').read())\ndvd_positive_reviews = dvd_positive_reviews.findAll('review_text')\n\ndvd_negative_reviews = BeautifulSoup(open('../input/ass4-nlp-train/dvdnegative.review').read())\ndvd_negative_reviews = dvd_negative_reviews.findAll('review_text')\n\nelectronics_positive_reviews= BeautifulSoup(open('../input/positivereview/positive.review').read())\nelectronics_positive_reviews = electronics_positive_reviews.findAll('review_text')\n\nelectronics_negative_reviews= BeautifulSoup(open('../input/sentimentanalyzer/negative.review').read())\nelectronics_negative_reviews = electronics_negative_reviews.findAll('review_text')\n\nkitchen_housewares_positive_reviews=BeautifulSoup(open('../input/ass4-nlp-test/positive.review').read())\nkitchen_housewares_positive_reviews=kitchen_housewares_positive_reviews.findAll('review_text')\n\nkitchen_housewares_negative_reviews=BeautifulSoup(open('../input/ass4-nlp-test/negative.review').read())\nkitchen_housewares_negative_reviews=kitchen_housewares_negative_reviews.findAll('review_text')\n\n\n\n\n#make shuffling\nnp.random.shuffle(book_positive_reviews)\nnp.random.shuffle(book_negative_reviews)\n\nnp.random.shuffle(dvd_positive_reviews)\nnp.random.shuffle(dvd_negative_reviews)\n\nnp.random.shuffle(electronics_positive_reviews)\nnp.random.shuffle(electronics_negative_reviews)\n\n\nnp.random.shuffle(kitchen_housewares_positive_reviews)\nnp.random.shuffle(kitchen_housewares_negative_reviews)\n\n\n\n\nprint(len(book_positive_reviews))\nprint(len(book_negative_reviews))\nprint(len(dvd_positive_reviews))\nprint(len(dvd_negative_reviews))\nprint(len(electronics_positive_reviews))\nprint(len(electronics_negative_reviews))\n\n\n\n\nimport nltk\nnltk.download('stopwords')\nnltk.download('wordnet')\nnltk.download('punkt')\nnltk.download('averaged_perceptron_tagger')\nimport numpy as np\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nimport bs4 as bs\nimport urllib.request\nimport re\nimport nltk\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.linear_model import LogisticRegression\nfrom bs4 import BeautifulSoup","metadata":{"execution":{"iopub.status.busy":"2022-06-02T21:17:20.109127Z","iopub.execute_input":"2022-06-02T21:17:20.109502Z","iopub.status.idle":"2022-06-02T21:17:24.893021Z","shell.execute_reply.started":"2022-06-02T21:17:20.109471Z","shell.execute_reply":"2022-06-02T21:17:24.892194Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n1000\n1000\n1000\n1000\n1000\n1000\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /usr/share/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"\npreprocessing for sentances then get labels from file name zero for negative sentance and one for positive sentance then put all sentances of train files in x_train0,and its labels in y_train0and put all sentances of test files in x_test0,and its labels in y_test0 then make sequance for train data and test data then make badded for them and finaly make train model","metadata":{}},{"cell_type":"code","source":"def preprocessing0(s):\n    processed_article = re.sub('[^a-zA-Z]', ' ', s )\n    processed_article = re.sub(r'\\s+', ' ', processed_article)\n    return processed_article\n#get tokenized data\nimport re\nbook_positive = []\nbook_negative = []\ndvd_positive = []\ndvd_negative = []\nelectronics_positive = []\nelectronics_negative = []\nkitchen_housewares_positive = []\nkitchen_housewares_negative = []\nfor review in book_positive_reviews:\n    tokens = preprocessing0(review.text)\n    book_positive.append(tokens)\n            \nfor review in book_negative_reviews:\n    tokens = preprocessing0(review.text)\n    book_negative.append(tokens)\n            \n\n            \nfor review in dvd_positive_reviews:\n    tokens = preprocessing0(review.text)\n    dvd_positive.append(tokens)\n            \nfor review in dvd_negative_reviews:\n    tokens = preprocessing0(review.text)\n    dvd_negative.append(tokens)\n            \nfor review in electronics_positive_reviews:\n    tokens = preprocessing0(review.text)\n    electronics_positive.append(tokens)\n            \nfor review in electronics_negative_reviews:\n    tokens = preprocessing0(review.text)\n    electronics_negative.append(tokens)\n\nfor review in kitchen_housewares_positive_reviews:\n    tokens = preprocessing0(review.text)\n    kitchen_housewares_positive.append(tokens)\n    \nfor review in kitchen_housewares_negative_reviews:\n    tokens = preprocessing0(review.text)\n    kitchen_housewares_negative.append(tokens)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T21:17:30.032986Z","iopub.execute_input":"2022-06-02T21:17:30.033360Z","iopub.status.idle":"2022-06-02T21:17:31.058769Z","shell.execute_reply.started":"2022-06-02T21:17:30.033328Z","shell.execute_reply":"2022-06-02T21:17:31.057922Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#prepare labels for each file\ndef prepare_labels(file,label):\n    labels=[]\n    for i in range(len(file)):\n        labels.append(label)\n    l=np.array(labels)\n    return l\nbook_positive_label0=prepare_labels(book_positive,1)\nbook_negative_label0=prepare_labels(book_negative,0)\ndvd_positive_label0=prepare_labels(dvd_positive,1)\ndvd_negative_label0=prepare_labels(dvd_negative,0)\nelectronics_positive_label0=prepare_labels(electronics_positive,1)\nelectronics_negative_label0=prepare_labels(electronics_negative,0)\nkitchen_housewares_positive_label0=prepare_labels(kitchen_housewares_positive,1)\nkitchen_housewares_negative_label0=prepare_labels(kitchen_housewares_negative,0)\ntrain_data0=[book_positive,book_negative,dvd_positive,dvd_negative,electronics_positive,electronics_negative]\ntrain_label0=[book_positive_label0,book_negative_label0,dvd_positive_label0,dvd_negative_label0,electronics_positive_label0,electronics_negative_label0]\ntest_data0=[kitchen_housewares_positive,kitchen_housewares_negative]\ntest_label0=[kitchen_housewares_positive_label0,kitchen_housewares_negative_label0]","metadata":{"execution":{"iopub.status.busy":"2022-06-02T21:17:36.179132Z","iopub.execute_input":"2022-06-02T21:17:36.179929Z","iopub.status.idle":"2022-06-02T21:17:36.190093Z","shell.execute_reply.started":"2022-06-02T21:17:36.179892Z","shell.execute_reply":"2022-06-02T21:17:36.189126Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nx_train0=np.concatenate(train_data0,axis=0)\nprint(x_train0.shape)\ny_train0=np.concatenate(train_label0,axis=0)\nprint(y_train0.shape)\nx_test0=np.concatenate(test_data0,axis=0)\nprint(x_test0.shape)\ny_test0=np.concatenate(test_label0,axis=0)\nprint(y_test0.shape)\nfrom keras.preprocessing.text import Tokenizer\n# prepare tokenizer\nt = Tokenizer()\nt.fit_on_texts(x_train0)\nvocab_size = len(t.word_index) + 1\n# integer encode the documents\nencoded_docs0 = t.texts_to_sequences(x_train0)\nxtr=[]\nfor i in encoded_docs0:\n    xtr.append(np.array(i))\nxtrain0=np.array(xtr)\nprint('encoded_train:\\n',xtrain0)\n\nfrom keras.preprocessing.text import Tokenizer\n# prepare tokenizer\nt = Tokenizer()\nt.fit_on_texts(x_test0)\ntvocab_size = len(t.word_index) + 1\n# integer encode the documents\ntencoded_docs0 = t.texts_to_sequences(x_test0)\nxte=[]\nfor i in tencoded_docs0:\n    xte.append(np.array(i))\nxtest0=np.array(xte)\nprint('encoded_test:\\n',xtest0)\n\nd=[]\nfor i in xtrain0:\n    d.append(len(i))\n    \nmaxsize=max(d)\nfrom keras.preprocessing.sequence import pad_sequences\nmax_length = maxsize\npadded_train0 = pad_sequences(xtrain0, maxlen=max_length, padding='post')\nprint('padded_train:\\n',padded_train0)\n\nfrom keras.preprocessing.sequence import pad_sequences\nmax_length = maxsize\npadded_test0 = pad_sequences(xtest0, maxlen=max_length, padding='post')\nprint('padded_test:\\n',padded_test0)\n\nfrom sklearn.tree import DecisionTreeClassifier\nclf_gini = DecisionTreeClassifier(criterion = \"gini\",random_state = 200,max_depth=10, min_samples_leaf=5)\n# Performing training\nclf_gini.fit(padded_train0,y_train0)\nprint(\"Classification rate: \",clf_gini.score(padded_test0,y_test0))\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\ny_pred=clf_gini.predict(padded_test0)\nprint (\"Accuracy : \",accuracy_score(y_test0,y_pred)*100)\nprint(\"Report : \",classification_report(y_test0, y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-06-02T21:18:39.413146Z","iopub.execute_input":"2022-06-02T21:18:39.413521Z","iopub.status.idle":"2022-06-02T21:18:43.374212Z","shell.execute_reply.started":"2022-06-02T21:18:39.413490Z","shell.execute_reply":"2022-06-02T21:18:43.372579Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"(6000,)\n(6000,)\n(2000,)\n(2000,)\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:20: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","output_type":"stream"},{"name":"stdout","text":"encoded_train:\n [array([   10,    57,  1075, 20816, 14714,    13,     1,   161,     5,\n         1176,   943,  2860,    54,     5,     1,  2260,   778,     5,\n          944, 14715,    43,     8,    11,   128,  1021,     5,   587,\n          448,    15,   131,    11,    44,   886,    63,   758,     2,\n          106,    14,  1283,    32,     1,   128,    65, 14715,   634,\n         2703,    12, 20817, 14714,   102,    19,    22,   139,  9168,\n            2,    46,   255,     4,  6785,  1650,    24,    36,  6786,\n         7424,  1029,  1246, 12384,   943,     2,   107,   609,  6787,\n          327,     1,    24,     8,   255,    12,  1700,     7,  2438,\n           17,     4,  1111,   666,   510,     3,     1,  8099,    10,\n           29,     5,   169,     1,   161,     5,  1176,   943,     8,\n            1,    95,     5,     4,   374,    11,  1193,  1419,    52,\n            4,  2200,  2102, 12385,     1,  6263,   478,     1,    95,\n            8,   214,   121,     1,  1166,     5,     1,  2201,    13,\n          259,   175,   842,    20,    35,   747,     3,   142,   140,\n            3,   502,    17,     3,   118,    39,   597, 20818,    90,\n        12386,    39,   598,   331,  3246,    39,  1530,   789,     4,\n         1679,  4627,     2,     4, 20819,     2,    35,  1259,   500,\n        14716,    15,   110,   943,    27,     8,  4172,     1, 20820,\n            2,  4173,   842,     5,    39,   479,  8100, 20821,    55,\n          569,   296,  1465,     1,    70,     8,  3138,     4,   644,\n           55,  2506,  2572,  3375,   432,     2,    46,    37,  5456,\n          598,    55,  6264,   141,    29,     1,   131,    23,  7425,\n         4865,    33,     9,    83,   167,   488,    90,     4,    69,\n            1,  1396,    55,   901,     1,   597,    49,   317,  1545,\n           37,  1789,    42,    12,    61,   802,   291,    10,     1,\n          410,     9,     8,  1339,     2,  1358,   264,     6,   135,\n            7,    50,   964,     7,    13,  8101,     3,   125,     3,\n          194,     9,    24,     3,     4,  1441,   679,    18,     6,\n          116, 20822,    81,    43,    23,   297,   278,     5, 20823,\n            2, 14717,   475,   224,  2260,   943,    11,    94,  3376,\n           57,    91,    18,     6,    60,   126,   874,     9,    24,\n          635,   271])\n array([    9,   790,   193,   197,    10,   635,   353,     6,   105,\n          779,    34,     4,   356,    13,   610,     3,     4,     2,\n            6,   108,    19,  1340,   233,     1,   791,   790,     8,\n          454,  4866,     1,  5457,     8,     4,   240,    48,  5458,\n           18,     5,     1,   281,   148,     6,    22,    38, 20824,\n        20825,     9,    27,  1442,     1,  5457,     1,   136,    51,\n         6265, 14718,    51,  1680,  9169,    33,    14,    23,   257,\n           12,     4,  2202,   101,     5,  1531,     9,     8,     7])\n array([    9,    24,    16,    50,  9170,     2,    85,   255,     7,\n          393,    11,  1466,  2326,  2933,    16,     3,  1443,     4,\n          557,     2,   578,   953,     2,    35,  5796,     1,   365,\n           11,    35,  1568,     7,    20,     4,   875,    12,  2152,\n          350,  3247,     8,    45,   152,   141,    10,   821, 20826,\n          393,    11,     7,    16,  3659,   557,   405,  1727,   181,\n           19,    30,  9171,    45,    35,  1309,   147,   141,   953,\n            9,    24,   393,    11,  2384,   102,    19,  2153,  1284,\n         2704,    35,    46,  7426,  1503,     2,  2507,  1194,     5,\n           65,     3,   427,     4,   802,   514,     5,    64,    35,\n           44,    26, 20827])                                          ...\n array([   43,    16,     4,  3712,  7422,    17,     1,   231,    68,\n           52,     6,   310,  1328,  4378,    12,     1,   973,   231,\n          516,   345,    20,  1716,    18,     1,   580, 30784,     8,\n         1233,     2,   193,   209,     7,   144,   465,     7,    16,\n          309,     5,     4,  1189,     3,  3361,     1,   231,   148,\n           64,    23,  1774,    17,   215,  1357,     6,   818,     7,\n         1432,    81,     5,     1,  7422])\n array([  79,   23,  508, 2045,    7,   13,   96, 2063,    2,   60, 2111,\n           1, 1147,  164,   33,   14,  138,  440,    8,  307,  204,  403,\n           7,  245,   26,  918,   17,    1, 1476,  423,   28,  144,  508,\n          85])\n array([    7,    13,    19,   397,     6,   142,     4,   178,    11,\n           13,    20,   848,    20,     9,     1,  1931,   190,     8,\n           50,   761,     2,   209,    92,  2949,     4,  1189,   964,\n          201,     1,   455,     2,  1001,     5,     1,   455,  2602,\n           17,    63,   440,  1837,     1,   231,    32,     4,  1986,\n          315,    23,   223,     5,     1,  2080,  5819,    10,   285,\n            3,   502,     4, 30785,  2660,    18,    11,    13,    19,\n            1,   120,   223,     1,   120,   223,    20,    32,   221,\n           27,    70,  1094,    46,  1612,     8,    11,   215,     5,\n            1,   834,  1129,  3194,     4,   383,   916,   795,    31,\n          140,   911,     9,    10,  2825,     5,     1,   211,    11,\n           75,   106,  3977,   104,     5,     1,   834,     2,   654,\n           76,    10,     1,  1599,    92,     5,     1,    65,     1,\n           59,  1225,     6,   105,   135,     8,     3,   177,     1,\n          487,    47,     5,   231,     2,   186,     7,   123,    10,\n           89,     7,    60,    97,    12,     4,   226,    31,   110,\n            6,  1489,     7,    94,    26,    42,     1,   643,    18,\n           33,    30,    89,    75,    83,  2759,   643,    11,    83,\n          330,    17,   122,   335,     6,    73,     4,   168,    53,\n          246,     5,     9,   231,     2,     5,   321,    43,    23,\n            4,   480,   173,   153,    18,    47,   386,    46,    88,\n            1,  2127,     1,   834,    22,    88,   180,    70,    67,\n            4,  1189])                                                ]\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:33: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","output_type":"stream"},{"name":"stdout","text":"encoded_test:\n [array([ 408,   10,   57, 1602,   19,   13,  118,   30,   46,   11,   57,\n        2859, 1603,    7,  729,    1, 1604, 5413,  237,    8,   29,  334,\n          29,  105,  178,    2,   77,  715,  169,  715,   50,    2,   21,\n          24,  384,   15,    1,   87,  820,   22,   23, 5414,    4,    1,\n         400,    8,    5, 4036,  603, 3319,    4,    5,   44,   78,   75,\n          56,   38,   13, 1280,   10])\n array([  65,  129,   26, 1605, 1045,  934,    4,  447, 3320,   10,  342,\n          54,  140,  635, 5415, 2036,  674,  472,  118,   28,    5,  215,\n          56, 2037,   15,    5,  636, 4037, 4038])\n array([ 536, 5416,   89,    3,   27,    5, 2860,    4,  129,   52,    2,\n         287,    1, 5417,  537,  268,  300,    4,   81,  384,   15,   32,\n           1,  221,  318,    9,  300,   22,   32, 1215,  140,  769,   52,\n           4,   15,  730,    4,   22,   23,   76,   29,  770,    6,   30,\n        1115,    6,    1, 4039,  537, 5418,  790,  155, 3321])\n ...\n array([   2,   77,    9,   82,    3,   21,   52, 1199,   62,  771,    4,\n         555,  108,   54,  177,   70,  540, 2805,    2, 3255,    3,   41,\n         117,   26,   52,   26,   16,  205,  180,  540,  390,   12,    2,\n         420,  253,    1,   87,   47,    2,   63,    3,   26,  659,   26,\n           3,  112,   40,    6, 9516,    1,  199,  349,    6, 9517,    4,\n        1379,  227,    1,  170,  100,  264,    1, 2429,  142,   73,    4,\n         370,   12,  328,   11,   16,  206,  153,    1,  291,    7,    1,\n         390,    4,   18,    1,  261,    1,  199,    8,    1,  655,   37,\n          87,    2,  214,  353,    2,   21, 1270,    5,  790,  690,   31,\n         182,   18,   16,  199,   89,    2, 1762,    9,    8,    1,  123,\n           3,   21,  393,    2,   97,    5, 1754,  935,   11,    3,   88,\n         576,  129,   44,   19,   11,    9,  540,  390,    3,  816,    6,\n         200, 2774,   15,   53,  673,  443,   82,    3, 4001,  184,    1,\n        2706,  199,    1,   55,  123,    6, 1281,    1, 2429,   73,    4,\n           1, 9518, 9519, 9520,  199,    8,    6,  131,    5,  497,  891,\n         318,  331,    7,    1,  199,   19,   67,    9, 1012, 1340,   82,\n           1,  891,  404, 5348,    4,  100, 1056,    6,  827,   18,    1,\n         261,   17,    6, 1006,  120,  363,    5,  745, 2838,    2,   66,\n          20,  150,   16,  497,  891,  480,    8,   75, 1214,   35,   11,\n         701,   36,   22,  393,    9,    2,  411,    2,  118,  292,    9,\n          19,    2, 1147,  253,    1, 1696])\n array([   2,   90,    1,  719,    4,    1,  132, 1724,   19,  220,    1,\n        1138,  155,   18,   25,  662, 1414,    4, 5150,   76,    1,  662,\n           8, 2477, 3965,   18,    1,  741,    7,    1, 2117,   66,   20,\n         939,   82,    2,   66,   20,   30,    3,   18, 1414, 5151,  553,\n          31,  144])\n array([  42, 2459,   10,    9,   26,    5,  756,  299,    4,  109,  283,\n           6,  167,    1,  212,  486, 3279,   11,  312,    1,   87,    4,\n         281,  219,   42, 1367,   40,    3,   27,    5,   29,  910,   71,\n          83,  267,    3,   38,   20,  289, 2788,  137,  543,    6,  417,\n        2322,   38,   20,   28,  605,   11,    5,  193,   38,   20,   28,\n          63,   18,    1,  836,    4,   38,   20,   28,   63,    6, 3835,\n          13,   38,   20,   30,    1, 9521,  343,   10, 9522, 9523,   88,\n           8,  311,    2,  332,   46, 2200, 1104,  139,   20,  842,   13,\n           6,  507,    1,  219,   11,    1,  249,    6,  758,    1, 2958,\n           2, 1762,  165,    7,    1,   70,  191, 1764,   61,    1, 9524,\n          83,   19,    2,   34,  214,    2,  258,  607,   39,   12,    1,\n        2487,  139,   20,   14,    6,   28, 1840,    6,   13,    6, 2015,\n         417])                                                           ]\npadded_train:\n [[  10   57 1075 ...    0    0    0]\n [   9  790  193 ...    0    0    0]\n [   9   24   16 ...    0    0    0]\n ...\n [  43   16    4 ...    0    0    0]\n [  79   23  508 ...    0    0    0]\n [   7   13   19 ...    0    0    0]]\npadded_test:\n [[ 408   10   57 ...    0    0    0]\n [  65  129   26 ...    0    0    0]\n [ 536 5416   89 ...    0    0    0]\n ...\n [   2   77    9 ...    0    0    0]\n [   2   90    1 ...    0    0    0]\n [  42 2459   10 ...    0    0    0]]\nClassification rate:  0.523\nAccuracy :  52.300000000000004\nReport :                precision    recall  f1-score   support\n\n           0       0.52      0.67      0.58      1000\n           1       0.53      0.38      0.44      1000\n\n    accuracy                           0.52      2000\n   macro avg       0.53      0.52      0.51      2000\nweighted avg       0.53      0.52      0.51      2000\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# in code 2 after got sequances make tokonization for its and for each word get embedded vector using pretrained model(GoogleNews-vectors) and make it as input for model and got accuracy of 58%","metadata":{}}]}